# 클라우드 컴퓨팅

## Amazon EC2 규모 조정

> 온프로미스와 데이터 센터에는 딜레마가 있다.

- 24시간 기준으로 변할 수도 있고 워크로드가 많은 시즌이 있거나 수요가 발생하지 않는 기간이 있을 수도 있다.

    + 데이터 센터를 구축하는 경우 중요한 문제는 하드웨어를 얼마나 구매할 것인가
    + 위와 같은 문제를 해결하기 위해 평균치를 적용한다면?
        * 피크에서 서버가 터지고
        * 적은양의 서버를 사용하는 경우 자원이 낭비된다.
    + 해당 딜레마는 온프레미스 환경에서는 해결이 불가능하지만 클라우드 환경에서는 쉽게 해결이 가능하다.


## 확장성

> 확장성을 위해서는 필요한 리소스만으로 시작하고 확장 및 축소를 통해 수요 변화에 자동으로 대응하도록 아키텍처를 설계해야 합니다.

- EC2 Auto Scaling을 사용하면 사용한 리소스에 대해서만 비용을 지불
- 컴퓨팅 용량 부족 때문에 고객의 요구 사항을 충족할 수 없을 수 없다.

### Auto Scaling

- 사용량에 따라 자원을 추가하거나 제거할 수 있다.
- 인스턴스를 자동으로 조정하여 애플리케이션 가용성을 효과적으로 유지할 수 있다.
- `동적 조정`은 수요 변화에 대응
- `예측 조정`은 예측된 수요데 따라 적절한 수의 Ec2 인스턴스를 자동으로 약

### 수직적 확장과 수평적 확장

- `수직적 확장`은 하나의 서버에 모든 기능을 몰아주고 하나의 컴퓨터의 성능을 향상시키는 확장방법
    + 일부 환경에서는 더 좋을 수 있지만, 유연성이 많이 결여되는 모습을 보여준다.

- `수평적 확장`은 개별적으로 문제를 해결하기 위해 오버프로비저닝하는 대신 프로세스의 각 부분으로 확장할 수 있다.


## Elasitc Load Balancing, ELB
> ELB는 획일적인 작업부담을 줄이기 위해 사용된다.

- ELB는 자동으로 확장된다.
- Auto Scaling 서비스는 Elasitc Load Balancing에 인스터스가 트래픽을 중지한 후 기존 요청이 완료될 때까지 기다린 다음 비운다.

- 이 작업이 끝나면 Auto Scaling 엔진은 기존 고객에 대한 중단을 유발하지 않고도 인스턴스를 종료할 수 있다.

- ELB는 외부 트래픽에만 사용되는 것이 아니라 서버 내부에서 서버간에서도 사용된다.

- ELB는 들오오는 애플리케이션 트래픽을 Amazon Ec2 인스턴스와 같은 여러 리소스에 자동으로 분산하는 AWS 서비스

- Auto Scaling 그룹으로 들어오는 단일 접점.


## 메시징 및 대기열
> 시스템에 일종의 버퍼나 대기열을 도입하면 프로세스가 훨씬 개선될 것입니다.

- 메시지를 완충 기억 장치에 배치한다는 개념을 메시징 혹은 대기열이라고 한다.
- 완충 기억 장치없이 직접 통신하는 것을 미결합된 아키텍처의 대표적인 예입니다.
    + 애플리케이션 A가 애플리케이션 B에 메시지를 직접 보낼 때 애플리케이션 B에 장애가 발생하면 애플리케이션 A에도 오류가 발생
- 완충 기억 장치를 도입한 소결합된 아키텍처를 애플리케이션 B에 오류가 발생해도 A는 오류와 상관없이 본인의 역할을 수행할 수 있습니다.

- 완충 기억 서비스로 `Amazon Simple Queue Service, SQS`와 `Amazon Simple Notification Service, SNS`가 있습니다.
    + `SQS 대기열`은 메시지가 처리되기 전까지 배치되는 곳.
        * 자동으로 규모 조정이 이루어지고 안정적
    + `SNS`는 메시지를 서비스에 전달하는 데 사용한다는 점에서 SQS와 다름

## 추가 컴퓨팅 서비스

> EC2를 사용할 때는 사용자가 새 소프트웨어 패키지가 출시되면 인스턴스 패치를 직접 책임지고 인스턴스의 규모 조정을 설정하고, 솔루션이 가용성이 높은 방식으로 호스팅되도록 아키텍처를 설계했는지 확인해야 합니다. 여기서 서버리스라느느 용어가 나옵니다.

### 서버리스

> AWS는 다양한 서버리스 컴퓨팅 옵션을 제공합니다. 서버리스는 마치 서버가 없는 것처럼 관리할 필요가 없다는 뜻입니다.

- 프로비저닝, 규모 조정, 고가용성 및 유지 관리와 관련된 모든 기본적인 환경 관리를 AWS가 대신 처리해줍니다.
    + 애플리케이션만 관리하면 됨.

- AWS Lambda는 이러한 서버리스 컴퓨팅 옵션 중에 대표적인 서비스
- Lambda는 사용자가 코드를 Lambda 함수라는 곳에 업로드할 수 있게 도와주는 서비스.
- Lambda 함수에서 서비스가 트리거를 기다립니다. 그리고 트리거가 감지되면 코드가 관리형 환경에서 자동으로 실행됩니다.
- 트리거가 하나만 있든 천 개가 있든 Lambda는 수요에 맞게 함수의 규모를 조정.
- Lambda는 코드를 15분 미만으로 실행하도록 설계되었기 때문에 딥 러닝 같은 실행 프로세스에는 적합하지 않다.
    + 웹 서비스의 백엔드나 요청 처리, 백에드 비용 보고 처리 서비스처럼 각 처리를 완료하는데 15분이 걸리지 않는 빠른 처리에 더 적합하다.

## ECS, EKS
> 서버리스를 이용할 준비가 되지 않았거나 혹은 기본 환경에 액세스해야 하지만 여전히 효율성과 휴대성이 필요한 상황도 있을 수 있다.

- 두 서비스 모두 컨테이너 오케스트레이션 도구.
- 이 서비스의 컨테이너는 Docker의 컨테이너
- 단일 컨테이너뿐만 아니라 컨테이너 클러스터를 관리해야하는 상황에서 사용할 수 있는 서비스
- `ECS`는 자체 컨테이너 오케스트레이션 소프트웨어를 관리하는 번거로움 없이도 컨테이너화된 애플리케이션을 대규모로 실행하는 데 도움이 되도록 설게.
- `EKS`는 `ECS`와 비슷한 작업을 수행하지만 다른 도구와 다른 기능을 제공.
- `EKS`와 `ECS`는 모두 EC2에서 실행할 수 있다.

### Fargate
> ECS 또는 EKS용 서버리스 컴퓨팅 플랫폼입니다. 기존의 방식의 애플리케이션을 호스팅하고자 하고 Linux나 Windows 같은 기본 운영 체제에 대한 완전한 액세스를 원한다면 EC2, 단기적인 실행 핫무나 서비스 지향 또는 이벤트 기반 애플리케이션을 호스팅하고자 한다면 AWS Lambda


### 서버리스 컴퓨팅
> `서버리스`라는 용어는 코드가 서버에서 실행되지만 서버를 프로비저닝하거나 관리할 필요가 없다는 뜻. 서버리스 컴퓨팅을 사용하면 서버를 유지 관리하는 대신 새로운 제품과 기능을 혁신하는 데 더 집중할 수 있다.

- 서버리스는 애플리케이션을 자동을 확장할 수 있는 유연성을 갖고 있다.
- 서버리스 컴퓨팅은 처리량 및 메모리와 같은 소비 단위를 수정하여 애플리케이션의 용량을 조절할 수 있다.
- AWS에서 서버리스용 서비스는 `AWS Lambda`가 있다.

### AWS Lambda
> 프로비저닝하거나 관리할 필요 없이 코드를 실행할 수 있는 서비스

- 컴퓨팅 시간에 대해서만 비용을 지불
    + 코드를 실행하는 동안에만 요금이 부과된다

- 예시, 업로드되는 이미지 크기를 AWS 클라우드에 맞춰 자동으로 조정하는 함수가 있다. 이 경우 새 이미지를 업로드할 때 함수가 트리거된다.

#### 작동방식
- 코드를 Lambda에 업로드한다.
- AWS 서비스, 모바일 애플리케이션 또는 HTTP 엔드포인트와 같은 이벤트 소스에서 트리거되도록 코드를 실행
- Lambda는 트리거된 경우에만 코드를 실행한다.

## 컨테이너
> 컨테이너는 애플리케이션의 코드와 종속성을 하나의 객체로 패키징하는 표준 방식을 제공. 보안성, 안정성, 확장성 요구 사항이 매우 중요한 프로세스 및 워크플로에도 컨테이너를 사용,

