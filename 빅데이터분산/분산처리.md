## 빅데이터 분산

### Scale-up
기존의 서버를 보다 높은 사양으로 업그레이드.

- 네트워크 상황 고려 하지 않고 성능 향상 가능.
- 서버 성능 향상에 비용 부담이 크고 한계가 명확함.
- 자연 재해와 같은 상황에서 대처가 많이 어렵다.
- 서버를 옮기거나 장비를 업그레이드하는 상황에 다운타임을 피할 수 없다.


### Scale-out
장비를 추가해서 숫자를 늘림.

- 확장의 유연성이 존재한다.
- 필요에 따라서 그때 그때 성능 향상이 가능하다.
- 아키텍처 설계가 많이 어렵다.
- 사용자 수가 급증하거나 데이터가 급증해도 프로그램이 멈추거나 성능이 크게 떨어지지 않는다.

### Divide and Conquer
- 정렬이나 검색에 흔히 사용되는 용어. 복잡하고 큰 문제를 여러개로 나누어 처리
- 같은 수준의 문제를 해결하는 과정은 서로에게 영향을 주지 않음.
- Scale-out

### 분산처리의 필요성
- 각종 시스템 자원의 투명성을 보장

#### 투명성
- 투명성은 다수의 컴퓨터로 구성된 시스템을 가상화해 마치 한 대의 컴퓨터 시스템인 것처럼 만드는 특징.
- 파일, 입출력 장치, 프로그램, 데이터베이스 시스템 등의 자원이 어떤 컴퓨터에 있는지 알 필요 없이 이용.
- 자원을 한 컴퓨터에서 다른 컴퓨터로 이동시켜도 사용자가 이를 의식하지 않고 자원을 이용
- 동일한 자원이 다수의 컴퓨터에 존재하고 있더라도 사용자에게는 하나의 자원으로 보이게 한다.
- 일부 구성 요소가 장애를 일으켜도 서비스를 제공할 수 있다.
- 구성 요소 추가하거나 제거하는 등 규모 변화에 대해서 사용자는 의식하지 안혹 시스템을 사용할 수 있다.

### 클러스트
- 다수의 컴퓨터와 네트워크를 묶어놓은 단위.
- 로드 밸런싱을 통해 클러스터로 구성한 어러 대의 컴퓨터에 나눠 처리.
- 빅데이터 분석을 위해 데이터를 나누고 나뉜 데이터를 클러스터링한 각 컴퓨터에 보내 처리.

### HDFS Architecture
 
#### NameNode
- metadata를 관리하는 Namenode와 실제 데이터에 대한 처리를 담당하는 Datanode로 구성.
- 파일, 디렉터리에 대한 metadata 보유
- Datanode 모니터링을 통한 장애 판단
- Datanode의 장애 발생 시 데이터 블록을 새로운 Datanode 또는 여유 있는 Datanode에 저장하는 블록 관리'
- editslog와 메모리의 fsimage를 이용한 체크포인트 작업

#### Datanode
- 실 데이터인 파일인 Block 저장
- 파일의 Block 크기는 64/128MB.
- Namenode에 3초 마다 Heart bit 신호 전송

### MapReduce
- 구글 웹 데이터 분석 모델
- 페타바이트 이상의 대용량 데이터를 저사양 컴퓨터로 구성된 클러스터로 처리하는 것이 목표.
- Map(), Reduce() 구현함으로써 처리해야할 데이터 병렬화가 목적.
- Map(), Reduce()만 구현하면 뒷단의 복잡한 분산 처리 과정은 프레임워크가 처리.
- 각 컴퓨터는 서로 매우 약한 상관 관계를 가지고 있기 때문에, 수백~수천 대까지 확장할 수 있다.
- 많은 수의 컴퓨터를 사용해 처리하기 때문에 하드웨어 장애 등을 항상 고려

